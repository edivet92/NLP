{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66ab304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa903af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af1f9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec52b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e971d8d",
   "metadata": {},
   "source": [
    "Ğ”Ğ°Ğ»ĞµĞµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ñ‚ĞµĞºÑÑ‚, ÑÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¸Ğ· Ğ¼Ğ¾ĞµĞ¹ Ğ»Ğ¸Ñ‡Ğ½Ğ¾Ğ¹ Ğ¿ĞµÑ€ĞµĞ¿Ğ¸ÑĞºĞ¸ Ğ² Ñ‚ĞµĞ»ĞµĞ³Ñ€Ğ°Ğ¼Ğµ. Ğ—Ğ½Ğ°Ğº Ğ´Ğ¾Ğ»Ğ»Ğ°Ñ€Ğ° - Ñ‚Ğ¾ĞºĞµĞ½ ĞºĞ¾Ğ½Ñ†Ğ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91689e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Whole_text.txt', 'rb') as f:\n",
    "    text = f.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eb28823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ĞšÑƒÑ€Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ¹Ğ´Ñ‘ÑˆÑŒ? $ Ğ‘Ğ°Ğ±Ğ°ÑÑŒĞºÑƒ Ğ½Ğ°Ğ´Ğ¾ ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¾Ñ‚Ğ´Ğ°Ñ‚ÑŒ $ ĞĞ½Ğ° Ğ¶Ğµ ĞµÑ‰Ñ‘ Ğ½Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ° $ Ğ£Ğ¶Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ° Ğ¿Ğ¾Ğ» Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹ Ğ´Ğ»Ñ Ğ·Ğ°'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b8851a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "202c3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cf8da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d52ca54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18051c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1101940,), dtype=int64, numpy=array([116, 156, 153, ..., 142, 142,  17], dtype=int64)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, input_encoding='UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5e3a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5594b94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ĞšÑƒÑ€Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ¹Ğ´Ñ‘ÑˆÑŒ? $ Ğ‘Ğ°Ğ±Ğ°ÑÑŒĞºÑƒ Ğ½Ğ°Ğ´Ğ¾ ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¾Ñ‚Ğ´Ğ°Ñ‚ÑŒ $ Ğ"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(50):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b45bb6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab47826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d88367c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "186366b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a43c5f",
   "metadata": {},
   "source": [
    "## Create training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b5e3e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08864f76",
   "metadata": {},
   "source": [
    "## Build The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff37c801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32fe6769",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "          states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92cf5bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab15c52e",
   "metadata": {},
   "source": [
    "### Try the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e853cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 372) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93fd44cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  95232     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  381300    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,414,836\n",
      "Trainable params: 4,414,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96716d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d613e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 54, 249, 104, 131, 234, 149,  76,  73, 334,  19, 339,  30, 237,\n",
       "        31,  89, 108, 195, 349, 118, 226,  79, 110, 141,  41, 316, 166,\n",
       "       173, 246, 292,  98, 359, 151, 234, 123, 235, 184, 124, 207,  61,\n",
       "       106, 343, 228, 331, 156, 164,   1, 197, 282,  80, 141, 361,  33,\n",
       "       337, 195, 139, 363, 219, 149, 278,  76,  65, 144,  91, 204, 308,\n",
       "        73, 137, 277, 162,  86,  71,  21,  30, 180, 131, 188, 288, 200,\n",
       "       315, 113, 366,  18,  65, 324, 142, 330, 140, 176, 168, 349,  78,\n",
       "       368, 217, 338, 355,  45, 167, 371, 265, 278], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baac7de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65e80490",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "203fc648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1d7d3e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fe383cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "170/170 [==============================] - 403s 2s/step - loss: 0.7741\n",
      "Epoch 22/30\n",
      "170/170 [==============================] - 484s 3s/step - loss: 0.7322\n",
      "Epoch 23/30\n",
      "170/170 [==============================] - 447s 3s/step - loss: 0.6935\n",
      "Epoch 24/30\n",
      "170/170 [==============================] - 456s 3s/step - loss: 0.6640\n",
      "Epoch 25/30\n",
      "170/170 [==============================] - 486s 3s/step - loss: 0.6366\n",
      "Epoch 26/30\n",
      "170/170 [==============================] - 486s 3s/step - loss: 0.6121\n",
      "Epoch 27/30\n",
      "170/170 [==============================] - 486s 3s/step - loss: 0.5912\n",
      "Epoch 28/30\n",
      "170/170 [==============================] - 482s 3s/step - loss: 0.5732\n",
      "Epoch 29/30\n",
      "170/170 [==============================] - 481s 3s/step - loss: 0.5606\n",
      "Epoch 30/30\n",
      "170/170 [==============================] - 483s 3s/step - loss: 0.5465\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=30, callbacks=[checkpoint_callback], initial_epoch=20, workers=6, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4bdd6ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_checkpoints\\\\ckpt_30'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('training_checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed3e8845",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0b8c9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e09320e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x195d00d25f0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('training_checkpoints/ckpt_30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "69246de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "170/170 [==============================] - 497s 3s/step - loss: 2.7583\n",
      "Epoch 32/100\n",
      "170/170 [==============================] - 499s 3s/step - loss: 1.8798\n",
      "Epoch 33/100\n",
      "170/170 [==============================] - 566s 3s/step - loss: 1.7566\n",
      "Epoch 34/100\n",
      "170/170 [==============================] - 543s 3s/step - loss: 1.6825\n",
      "Epoch 35/100\n",
      "170/170 [==============================] - 521s 3s/step - loss: 1.6294\n",
      "Epoch 36/100\n",
      "170/170 [==============================] - 499s 3s/step - loss: 1.5860\n",
      "Epoch 37/100\n",
      "170/170 [==============================] - 522s 3s/step - loss: 1.5516\n",
      "Epoch 38/100\n",
      "170/170 [==============================] - 544s 3s/step - loss: 1.5202\n",
      "Epoch 39/100\n",
      "170/170 [==============================] - 545s 3s/step - loss: 1.4935\n",
      "Epoch 40/100\n",
      "170/170 [==============================] - 544s 3s/step - loss: 1.4669\n",
      "Epoch 41/100\n",
      "170/170 [==============================] - 511s 3s/step - loss: 1.4436\n",
      "Epoch 42/100\n",
      "170/170 [==============================] - 516s 3s/step - loss: 1.4219\n",
      "Epoch 43/100\n",
      "170/170 [==============================] - 457s 3s/step - loss: 1.3999\n",
      "Epoch 44/100\n",
      "170/170 [==============================] - 419s 2s/step - loss: 1.3792\n",
      "Epoch 45/100\n",
      "170/170 [==============================] - 418s 2s/step - loss: 1.3583\n",
      "Epoch 46/100\n",
      "170/170 [==============================] - 450s 3s/step - loss: 1.3391\n",
      "Epoch 47/100\n",
      "170/170 [==============================] - 456s 3s/step - loss: 1.3185\n",
      "Epoch 48/100\n",
      "170/170 [==============================] - 455s 3s/step - loss: 1.3005\n",
      "Epoch 49/100\n",
      "170/170 [==============================] - 458s 3s/step - loss: 1.2808\n",
      "Epoch 50/100\n",
      "170/170 [==============================] - 454s 3s/step - loss: 1.2625\n",
      "Epoch 51/100\n",
      "170/170 [==============================] - 454s 3s/step - loss: 1.2450\n",
      "Epoch 52/100\n",
      "170/170 [==============================] - 447s 3s/step - loss: 1.2264\n",
      "Epoch 53/100\n",
      "170/170 [==============================] - 449s 3s/step - loss: 1.2069\n",
      "Epoch 54/100\n",
      "170/170 [==============================] - 445s 3s/step - loss: 1.1902\n",
      "Epoch 55/100\n",
      "170/170 [==============================] - 431s 3s/step - loss: 1.1725\n",
      "Epoch 56/100\n",
      "170/170 [==============================] - 449s 3s/step - loss: 1.1529\n",
      "Epoch 57/100\n",
      "170/170 [==============================] - 450s 3s/step - loss: 1.1347\n",
      "Epoch 58/100\n",
      "170/170 [==============================] - 449s 3s/step - loss: 1.1187\n",
      "Epoch 59/100\n",
      "170/170 [==============================] - 450s 3s/step - loss: 1.1024\n",
      "Epoch 60/100\n",
      "170/170 [==============================] - 448s 3s/step - loss: 1.0857\n",
      "Epoch 61/100\n",
      "170/170 [==============================] - 446s 3s/step - loss: 1.0690\n",
      "Epoch 62/100\n",
      "170/170 [==============================] - 450s 3s/step - loss: 1.0528\n",
      "Epoch 63/100\n",
      "170/170 [==============================] - 448s 3s/step - loss: 1.0383\n",
      "Epoch 64/100\n",
      "170/170 [==============================] - 448s 3s/step - loss: 1.0247\n",
      "Epoch 65/100\n",
      "170/170 [==============================] - 445s 3s/step - loss: 1.0084\n",
      "Epoch 66/100\n",
      "170/170 [==============================] - 415s 2s/step - loss: 0.9950\n",
      "Epoch 67/100\n",
      "170/170 [==============================] - 433s 3s/step - loss: 0.9814\n",
      "Epoch 68/100\n",
      "170/170 [==============================] - 478s 3s/step - loss: 0.9665\n",
      "Epoch 69/100\n",
      "170/170 [==============================] - 497s 3s/step - loss: 0.9551\n",
      "Epoch 70/100\n",
      "170/170 [==============================] - 533s 3s/step - loss: 0.9431\n",
      "Epoch 71/100\n",
      "170/170 [==============================] - 497s 3s/step - loss: 0.9317\n",
      "Epoch 72/100\n",
      "170/170 [==============================] - 545s 3s/step - loss: 0.9192\n",
      "Epoch 73/100\n",
      "170/170 [==============================] - 542s 3s/step - loss: 0.9090\n",
      "Epoch 74/100\n",
      "170/170 [==============================] - 518s 3s/step - loss: 0.8995\n",
      "Epoch 75/100\n",
      "170/170 [==============================] - 504s 3s/step - loss: 0.8857\n",
      "Epoch 76/100\n",
      "170/170 [==============================] - 470s 3s/step - loss: 0.8766\n",
      "Epoch 77/100\n",
      "170/170 [==============================] - 477s 3s/step - loss: 0.8678\n",
      "Epoch 78/100\n",
      "170/170 [==============================] - 538s 3s/step - loss: 0.8577\n",
      "Epoch 79/100\n",
      "170/170 [==============================] - 535s 3s/step - loss: 0.8493\n",
      "Epoch 80/100\n",
      "170/170 [==============================] - 538s 3s/step - loss: 0.8409\n",
      "Epoch 81/100\n",
      "170/170 [==============================] - 541s 3s/step - loss: 0.8330\n",
      "Epoch 82/100\n",
      "170/170 [==============================] - 485s 3s/step - loss: 0.8214\n",
      "Epoch 83/100\n",
      "170/170 [==============================] - 483s 3s/step - loss: 0.8158\n",
      "Epoch 84/100\n",
      "170/170 [==============================] - 481s 3s/step - loss: 0.8098\n",
      "Epoch 85/100\n",
      "170/170 [==============================] - 482s 3s/step - loss: 0.8017\n",
      "Epoch 86/100\n",
      "170/170 [==============================] - 482s 3s/step - loss: 0.7958\n",
      "Epoch 87/100\n",
      "170/170 [==============================] - 481s 3s/step - loss: 0.7881\n",
      "Epoch 88/100\n",
      "170/170 [==============================] - 482s 3s/step - loss: 0.7809\n",
      "Epoch 89/100\n",
      "170/170 [==============================] - 481s 3s/step - loss: 0.7780\n",
      "Epoch 90/100\n",
      "170/170 [==============================] - 482s 3s/step - loss: 0.7708\n",
      "Epoch 91/100\n",
      "170/170 [==============================] - 483s 3s/step - loss: 0.7609\n",
      "Epoch 92/100\n",
      "170/170 [==============================] - 482s 3s/step - loss: 0.7562\n",
      "Epoch 93/100\n",
      "170/170 [==============================] - 482s 3s/step - loss: 0.7532\n",
      "Epoch 94/100\n",
      "170/170 [==============================] - 482s 3s/step - loss: 0.7442\n",
      "Epoch 95/100\n",
      "170/170 [==============================] - 486s 3s/step - loss: 0.7391\n",
      "Epoch 96/100\n",
      "170/170 [==============================] - 482s 3s/step - loss: 0.7369\n",
      "Epoch 97/100\n",
      "170/170 [==============================] - 482s 3s/step - loss: 0.7311\n",
      "Epoch 98/100\n",
      "170/170 [==============================] - 473s 3s/step - loss: 0.7253\n",
      "Epoch 99/100\n",
      "170/170 [==============================] - 469s 3s/step - loss: 0.7200\n",
      "Epoch 100/100\n",
      "170/170 [==============================] - 477s 3s/step - loss: 0.7189\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=100, callbacks=[checkpoint_callback], initial_epoch=30, workers=6, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1c17db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/200\n",
      "170/170 [==============================] - 427s 3s/step - loss: 0.7167\n",
      "Epoch 102/200\n",
      "170/170 [==============================] - 424s 2s/step - loss: 0.7168\n",
      "Epoch 103/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.7121\n",
      "Epoch 104/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.7053\n",
      "Epoch 105/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.7033\n",
      "Epoch 106/200\n",
      "170/170 [==============================] - 414s 2s/step - loss: 0.6937\n",
      "Epoch 107/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6907\n",
      "Epoch 108/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6910\n",
      "Epoch 109/200\n",
      "170/170 [==============================] - 414s 2s/step - loss: 0.6888\n",
      "Epoch 110/200\n",
      "170/170 [==============================] - 415s 2s/step - loss: 0.6844\n",
      "Epoch 111/200\n",
      "170/170 [==============================] - 415s 2s/step - loss: 0.6798\n",
      "Epoch 112/200\n",
      "170/170 [==============================] - 413s 2s/step - loss: 0.6772\n",
      "Epoch 113/200\n",
      "170/170 [==============================] - 414s 2s/step - loss: 0.6708\n",
      "Epoch 114/200\n",
      "170/170 [==============================] - 415s 2s/step - loss: 0.6655\n",
      "Epoch 115/200\n",
      "170/170 [==============================] - 414s 2s/step - loss: 0.6658\n",
      "Epoch 116/200\n",
      "170/170 [==============================] - 413s 2s/step - loss: 0.6685\n",
      "Epoch 117/200\n",
      "170/170 [==============================] - 413s 2s/step - loss: 0.6678\n",
      "Epoch 118/200\n",
      "170/170 [==============================] - 414s 2s/step - loss: 0.6669\n",
      "Epoch 119/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6551\n",
      "Epoch 120/200\n",
      "170/170 [==============================] - 435s 3s/step - loss: 0.6640\n",
      "Epoch 121/200\n",
      "170/170 [==============================] - 412s 2s/step - loss: 0.6580\n",
      "Epoch 122/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.6475\n",
      "Epoch 123/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6423\n",
      "Epoch 124/200\n",
      "170/170 [==============================] - 412s 2s/step - loss: 0.6408\n",
      "Epoch 125/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.6422\n",
      "Epoch 126/200\n",
      "170/170 [==============================] - 411s 2s/step - loss: 0.6439\n",
      "Epoch 127/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.6373\n",
      "Epoch 128/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.6374\n",
      "Epoch 129/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6347\n",
      "Epoch 130/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.6350\n",
      "Epoch 131/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.6325\n",
      "Epoch 132/200\n",
      "170/170 [==============================] - 411s 2s/step - loss: 0.6309\n",
      "Epoch 133/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.6348\n",
      "Epoch 134/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.6336\n",
      "Epoch 135/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.6360\n",
      "Epoch 136/200\n",
      "170/170 [==============================] - 411s 2s/step - loss: 0.6256\n",
      "Epoch 137/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.6225\n",
      "Epoch 138/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.6269\n",
      "Epoch 139/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6237\n",
      "Epoch 140/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6251\n",
      "Epoch 141/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6221\n",
      "Epoch 142/200\n",
      "170/170 [==============================] - 407s 2s/step - loss: 0.6186\n",
      "Epoch 143/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.6272\n",
      "Epoch 144/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.6147\n",
      "Epoch 145/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6122\n",
      "Epoch 146/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6121\n",
      "Epoch 147/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6143\n",
      "Epoch 148/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6106\n",
      "Epoch 149/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.6165\n",
      "Epoch 150/200\n",
      "170/170 [==============================] - 412s 2s/step - loss: 0.6365\n",
      "Epoch 151/200\n",
      "170/170 [==============================] - 446s 3s/step - loss: 0.6349\n",
      "Epoch 152/200\n",
      "170/170 [==============================] - 443s 3s/step - loss: 0.6589\n",
      "Epoch 153/200\n",
      "170/170 [==============================] - 424s 2s/step - loss: 0.6506\n",
      "Epoch 154/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.6486\n",
      "Epoch 155/200\n",
      "170/170 [==============================] - 411s 2s/step - loss: 0.6276\n",
      "Epoch 156/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.6123\n",
      "Epoch 157/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.6146\n",
      "Epoch 158/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6171\n",
      "Epoch 159/200\n",
      "170/170 [==============================] - 407s 2s/step - loss: 0.6176\n",
      "Epoch 160/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.6043\n",
      "Epoch 161/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.6056\n",
      "Epoch 162/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6044\n",
      "Epoch 163/200\n",
      "170/170 [==============================] - 415s 2s/step - loss: 0.6005\n",
      "Epoch 164/200\n",
      "170/170 [==============================] - 418s 2s/step - loss: 0.6000\n",
      "Epoch 165/200\n",
      "170/170 [==============================] - 417s 2s/step - loss: 0.6209\n",
      "Epoch 166/200\n",
      "170/170 [==============================] - 419s 2s/step - loss: 0.6210\n",
      "Epoch 167/200\n",
      "170/170 [==============================] - 415s 2s/step - loss: 0.6365\n",
      "Epoch 168/200\n",
      "170/170 [==============================] - 411s 2s/step - loss: 0.6367\n",
      "Epoch 169/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.6887\n",
      "Epoch 170/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.8966\n",
      "Epoch 171/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.7933\n",
      "Epoch 172/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.7113\n",
      "Epoch 173/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.6727\n",
      "Epoch 174/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.6363\n",
      "Epoch 175/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6124\n",
      "Epoch 176/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.5927\n",
      "Epoch 177/200\n",
      "170/170 [==============================] - 417s 2s/step - loss: 0.5822\n",
      "Epoch 178/200\n",
      "170/170 [==============================] - 407s 2s/step - loss: 0.5847\n",
      "Epoch 179/200\n",
      "170/170 [==============================] - 407s 2s/step - loss: 0.5960\n",
      "Epoch 180/200\n",
      "170/170 [==============================] - 407s 2s/step - loss: 0.5866\n",
      "Epoch 181/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.6053\n",
      "Epoch 182/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.6011\n",
      "Epoch 183/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.6006\n",
      "Epoch 184/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.5884\n",
      "Epoch 185/200\n",
      "170/170 [==============================] - 407s 2s/step - loss: 0.5879\n",
      "Epoch 186/200\n",
      "170/170 [==============================] - 406s 2s/step - loss: 0.5914\n",
      "Epoch 187/200\n",
      "170/170 [==============================] - 406s 2s/step - loss: 0.5895\n",
      "Epoch 188/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.5990\n",
      "Epoch 189/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.6054\n",
      "Epoch 190/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6037\n",
      "Epoch 191/200\n",
      "170/170 [==============================] - 407s 2s/step - loss: 0.6039\n",
      "Epoch 192/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6230\n",
      "Epoch 193/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.6238\n",
      "Epoch 194/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6394\n",
      "Epoch 195/200\n",
      "170/170 [==============================] - 407s 2s/step - loss: 0.6505\n",
      "Epoch 196/200\n",
      "170/170 [==============================] - 407s 2s/step - loss: 0.6437\n",
      "Epoch 197/200\n",
      "170/170 [==============================] - 409s 2s/step - loss: 0.6357\n",
      "Epoch 198/200\n",
      "170/170 [==============================] - 408s 2s/step - loss: 0.6342\n",
      "Epoch 199/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6268\n",
      "Epoch 200/200\n",
      "170/170 [==============================] - 410s 2s/step - loss: 0.6486\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=200, callbacks=[checkpoint_callback], initial_epoch=100, workers=6, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e4c2daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./training_checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2d2c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "        skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "            values=[-float('inf')]*len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        # Run the model.\n",
    "        # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "        predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "        # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits/self.temperature\n",
    "        # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # Sample the output logits to generate token IDs.\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        # Return the characters and model state.\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b60de666",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars, temperature=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1d854d",
   "metadata": {},
   "source": [
    "ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ Ğ½ĞµĞ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97977925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, ĞºĞ°Ğº Ğ´ĞµĞ»Ğ°?ğŸ´Ğ”ğŸ˜‹fğŸ’‹L|ĞŸğŸ˜™ğŸ«¥ğŸ˜¡ğŸ’]ğŸ˜–Ğ–ğŸ˜†tğŸ¥ğŸ·Ñ‰Ğ¡ğŸ˜—.,ğŸ¤¢ğŸ˜¿SĞğŸ¤”Ñ‰ğŸ¥â„–Ğ¶Ğ—ğŸ˜…ğŸ·3ğŸ–IğŸ˜ŒğŸ˜SĞ“ğŸ«£ğŸ¤¯ğŸ”ºğŸ™ğŸ¥ºğŸ›ğŸ’©ğŸ˜œÃ«ğŸ¤¢ğŸ™ğŸ¤­cĞ¬ğŸ‘¯ğŸ¥—ğŸ‘‡vğŸ¤·ğŸ¥Ğ½ğŸ¥µâœˆ;â‰¤ğŸ˜ŠÂ \n",
      "1â—ğŸ¦Ğ—ğŸ¥ºğŸ¦ Ğ¿â¤ğŸ¤©pGwğŸ‘ˆğŸ¥—Ğ¸bâ‚½C_Ñ‚ğŸ‘ğŸ’‹ğŸš²Ğ¡9ÑƒğŸ§¡/p]Ğ§ğŸ¦ğŸ¤¨ğŸ˜©ğŸ˜ğŸ¤©vĞĞ²tğŸ™‚aĞ³ğŸ¤œĞ›Ğ˜Ugâ€™\\9,Ğ–Ğ§9â€˜Lâ„…ğŸ˜·Ğ¤â„…ğŸ¤¯Ğ!oÑğŸ§ wğŸ˜ğŸ·ğŸ˜˜Ğ“ğŸ¤ğŸ˜»ğŸ¥³ğŸ˜¡â„–ğŸ˜›FğŸ˜¯VğŸ˜‰â‰¤ğŸ¥º#.ğŸ¤ªĞ©Ğ•UğŸ·PLğŸ¥©ğŸ˜¡ÑĞAâ€“ğŸ«£Ñ†3â˜$â €ğŸ¥³â€”ğŸ˜šğŸ˜‚ğŸ˜½mğŸ•ğŸ¥‚ğŸ¥´ğŸ˜‡ğŸ»âš¡ğŸ’†ĞğŸµpâ„…ğŸ˜‡ğŸ•â—ğŸ¥ğŸ±Ğ«ğŸ˜•ğŸ´ĞğŸ˜–ğŸ˜©ğŸ˜¢FğŸ¤®ğŸ¥¹sAĞ©ğŸ«¥ğŸ˜]ğŸ˜Š\n",
      "ğŸ’• ğŸ˜¸Ğ»ğŸ˜¹ğŸ•ğŸ¤®ğŸ¤­ğŸ¤¤ğŸ˜âš¡/eğŸ§šğŸ¥ºĞœâš¡â˜€cĞ±EğŸ˜±ğŸ™ˆzâ˜ºğŸ˜†â€¢Ğ©\r",
      "ğŸ˜¸ğŸ‘ğŸ±ğŸ«£ğŸ’ªâ™‚ğŸ§šn:ğŸ¤—fÃ©Ğ¶ğŸ–ğŸªğŸ˜€ğŸ˜¸Ğ¹â‚½Ñ‰ğŸ…:â™»ğŸ˜„;lğŸŠâ‚½ğŸ˜…ğŸ˜ƒĞ›ğŸ‘ŒğŸ§ƒğŸŒ§ğŸ’•Ñˆ]=ğŸ¥°Ğ’0ğŸ•Ñ‘â€¢ğŸ…ğŸ‘6Ğ’ğŸ™€âœ…Î¼Ğ¯ğŸ¥ğŸ•mğŸ™ğŸĞĞ¬Jâ€¦â„…ğŸµ,ğŸ˜ğŸ¥µğŸ˜¹Â 'ĞœğŸ¤­Ğ¸â˜Ğ¦ğŸ±ğŸ˜µ]ĞšğŸ™‡3Ğ™vğŸ’ªğŸ‘Ğ¨âš¡iğŸ˜²ğŸ¥—â€”ğŸ˜´ğŸJtâ„…âœˆğŸš—ğŸ•&ğŸ˜¨ğŸ˜£K9Ğ¥j5\"ÑˆĞ¡%ğŸŒˆğŸ˜™ğŸ‹.ğŸ˜¸ğŸ˜©ğŸ’•â˜”ğŸ¤£ğŸ‘ˆĞ¹Ğ2ğŸ˜µÂ°IğŸ™€ğŸ¤¯ğŸâ™‚ğŸ¤‘ğŸ€Â«ğŸ‘†ğŸ¦ DÑŠğŸ‘¯Ğ¿nğŸ˜¯ğŸ¤ªğŸ™‚ğŸ˜ğŸ˜‹ğŸ¥³RğŸŒ§Ğ¹ğŸ«£ğŸ˜€-C'Ğ¡Ã«ğŸ¥ÑğŸ¤¯Â¡ğŸ˜”ğŸ¥¶Ğ¤lğŸ˜´ğŸ˜²ĞğŸˆbğŸ˜šğŸ™ğŸ«¶Ğ§ğŸ‘Ğ¯Ğ ğŸ˜€ğŸ¦œğŸˆlğŸ«¥ğŸ”ºğŸ¤¯ğŸ¤·Ğ§Ğ‘]bğŸ˜¢)â€˜=ĞSğŸ‘ˆğŸ¦ğŸ™ğŸ˜¨Ğ”PÑ…ğŸ˜€Ğ¤[ĞšĞ¤]ğŸ˜´ğŸ«¶DğŸ¥¶ğŸ‘oğŸ™‡ÑqğŸ˜šğŸ¤•ğŸ”¥ğŸ˜µMğŸ˜›ğŸ‘Ğ¾ğŸ’]lâ¤.:KğŸ¦\n",
      "Ñ…ĞºĞğŸ˜†hğŸ™ŒğŸ˜•ğŸ¦!ğŸ¼hğŸ˜¬ğŸ™€ÑĞ‘Â¡ğŸ‘ŒĞ™aâ¦ğŸ˜–ĞšxzğŸ§ Ğ¶ğŸ´â™»ğŸ˜œâ˜GĞ¡Ñ‹Ğ“ğŸ´Ğ·ğŸ‘€ğŸ˜—ğŸ˜¡ğŸ˜€lğŸ‘»ğŸ˜²Ğ¢ğŸ·â™»ğŸ˜½Ğ½ğŸªâ„…B|ğŸµğŸ¦œNĞ™D#ÑğŸ¤‘ğŸ¼ĞœğŸ‘cğŸ€ğŸ‘‡Ğ¯ğŸ™‡IğŸ˜fÑˆĞšğŸ¦Ğ›qĞŸâ€¦âœŒÂ«M3ğŸ’”ğŸ™ŒĞ’ğŸ‘â€”ğŸ¥´SNĞ¹Ğ£ğŸª™ğŸ˜’ğŸ‘ğŸ¥´Ñ†Ğ¹jğŸ˜¢ğŸ’¯$ğŸ“ğŸ‘†ğŸ˜‚ğŸ’›ğŸ¤¯0ob*thPÂ°ğŸ’ÑğŸ¤—JĞ—ğŸµğŸ¤©ğŸ¤¯ğŸ™ğŸ˜±ğŸŒ¹3ğŸ–ğŸ˜‚ğŸ™â™»ğŸ»fğŸĞ³ğŸ´/EĞ“\n",
      "ğŸŒ§ğŸ¤·ğŸ¦ĞğŸŒ¸&Hc4tğŸ˜‚ğŸ‘ğŸ¤Â¡KğŸ•9ğŸ¥µâ—ğŸ¥²PğŸ™ÑƒÑBĞ«ğŸ¥´Ğ‘ğŸ˜€:ğŸ”¥ğŸ™‚ğŸ™„ğŸ¤¯ğŸ˜‘ğŸ˜‡ğŸ…ğŸ’ƒğŸ˜»ğŸ˜‘ğŸ˜ˆĞœğŸ˜¥RğŸ‘»ğŸ˜“ğŸ‘€ğŸ˜£CLâ€˜'LÑĞ²ğŸ•ğŸ˜„ğŸ¥ğŸ‘ŒğŸ‹ğŸŒµğŸ’‹â €ğŸ¤¯Ã©:Ğ±ğŸ˜¿ğŸ˜‚ğŸ¤­ğŸ¥´Ğ«ğŸ˜›Ğ§ï¸Ñ‡^Ğ³Ñ‹ğŸ±ğŸ˜¥/fï¸ğŸ˜µğŸ¥³ğŸŠ5ğŸ¤‘ğŸ¤¤WÑ‡ğŸ¤‘ğŸ©¸ï¸Ğ•Ğ£Ğ›â„…ğŸ‘¯ğŸ˜¬RğŸ˜˜ğŸ˜@Ğ½ğŸ¥¦\\ğŸ™ğŸ˜ğŸ˜£(ĞœğŸ§šĞŸğŸ¤”Ğ¯Ğ–ğŸ¦¶7ğŸ¤—âš¡ğŸ™‡ğŸ˜˜@ZğŸ’WyğŸ˜¢ğŸŠğŸ«£ğŸŒ§ğŸ¤®â€¦Ğ®ğŸ˜†ğŸ˜‰ğŸ˜´ağŸ˜Œ;@lğŸŒˆğŸ˜œğŸ‘Œâ€“ğŸ’ƒğŸ˜€10ğŸ‘¯Ğ±ğŸ˜£ÑğŸ¶/ğŸ¥*Ğ©ğŸ™ŒğŸ¥¶ğŸ•ğŸ›ğŸ¤¨ğŸ˜‡ğŸŒ§Ñ€ÑŠğŸ±Ğ™ğŸ¤¨Â¿ğŸ•EYğŸ˜©HâœŒğŸš²ğŸ¶UğŸ™‚iĞ¯ğŸ€Â»ğŸ¥u:ğŸ¦œbğŸ¦œXğŸ˜­ğŸ˜‚4ğŸ¤¢ğŸ¥³ğŸ¤¤ğŸŒ¹ğŸ…iğŸ¦ÑÑ‘PğŸ˜¯ğŸ¥¦ğŸ˜ğŸ‘Ğ›â™»ÑğŸ¤©â¦yIĞğŸ¥ºğŸ»3Ñ‹ğŸ˜PBDğŸ˜¡Ğ§ğŸğŸ«£ğŸ´ğŸ˜ŠrÂ¡ğŸ˜€ğŸ˜•Ğ·ğŸ˜Ÿ[]Ã©ğŸŒµD/Ğ­Ğ 8ğŸ‘ĞğŸ§ÑğŸ­âœ…ğŸ‘ğŸ‘Â¿ğŸ¦ ğŸ…ğŸ˜ŸğŸ˜¯ğŸ¦œĞ™Ğ›PĞ¯Ğ£ğŸ¤©Ğ¼ğŸŒ¹â™‚ğŸŒµvĞµkâ€˜Â ğŸ“%â€”ğŸ˜ğŸ™ğŸ”¥ğŸ¥ºğŸ¥—zğŸ˜—HyğŸ™„oğŸ˜°ğŸŠ*ğŸ©¸:Ğ˜ğŸ™‹xğŸ¤­8ğŸŒ¸Ğ¥Ñ‡Ğ¼ğŸ™ğŸ˜‚N)ğŸ˜¹ğŸ˜±ğŸ˜¿Ñ†ğŸ»ğŸ¤œpğŸš—Ñƒ\r",
      "ğŸ˜˜ğŸ˜£ğŸ¤‘ğŸ«¥ğŸ˜™Ğ™Ñ‰ğŸ‘ğŸ˜¸uğŸ™ğŸ™€%ğŸ¦ğŸ˜»ğŸ˜‘/ğŸ’•ğŸ¤OğŸ˜¢ğŸ˜ğŸ™‚ğŸ¦ğŸ˜¨,ğŸ¤œ9%ÑŠğŸ¥³Ñ‹]ğŸ˜ˆğŸ« âœ…ğŸ¤®Ğ”ğŸ§š\r",
      "ğŸ‘ğŸ–ğŸ’›Ñ#ğŸ¤«jğŸ˜–ğŸ˜‰' Ğ®Ğ¯â€˜ğŸ¤ªğŸ’©dÃ«sğŸ’•â™‚) \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 8.070864915847778\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, ĞºĞ°Ğº Ğ´ĞµĞ»Ğ°?'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9482b858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2b02b31ddb0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('./training_checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dad0c9",
   "metadata": {},
   "source": [
    "ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "baddee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars, temperature=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f27d1dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, ĞºĞ°Ğº Ğ´ĞµĞ»Ğ°? $ ĞŸĞ¾ĞºĞ° ÑĞ¸Ğ´ĞµÑ‚ÑŒ Ñ‡Ñ‚Ğ¾ ĞµÑ‰Ğµ ĞºĞ°Ğ¿ĞµÑ† $ ĞŸÑ€Ğ¸ĞµÑ…Ğ°Ğ» $ ĞœĞ¾Ğ¶Ğ½Ğ¾, Ğ±ĞµĞ· ÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸ Ğ¿Ğ¾Ğ¶Ğ°Ñ€Ñ‹, Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ¾Ñ‡ĞµĞ½ÑŒ ĞºÑ€Ğ°ÑĞ¸Ğ²Ğ¾ $ ĞŸÑ€Ğ¾ÑÑ‚Ğ¸, Ğ·Ğ°Ğ¹Ñ‡Ğ¸Ğº, Ğ·Ğ°Ğ±Ğ¾Ğ»ĞµĞ» ÑĞ¸Ğ´ĞµĞ½ÑŒ, Ñ‚Ğ¾ Ğ¸ Ğ·Ğ°Ğ±Ñ‹Ğ»Ğ° Ğ½Ğ° Ğ¿Ñ€Ğ¸ĞµĞ¼Ğµ Ğ¶Ğ´Ğ°Ñ‚ÑŒ $ Ğ£ Ğ½Ğ°Ñ Ñ‚ÑƒÑ‚ Ñ‚Ğ¾Ğ½Ñ‡Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ $ Ğ¡ĞµĞ¹Ñ‡Ğ°Ñ Ğ²ÑÑ‚Ñ€ĞµÑ‚Ğ¸Ğ»ÑÑ ? $ Ğ’Ñ€Ğ¾Ğ´Ğµ Ğ±Ñ‹ Ğ´Ğ°Ğ¶Ğµ Ğ½Ğ° ÑĞ°Ğ½Ğ°Ñ†Ğ¸Ñ $ Ğ¡ÑƒĞ¿ĞµÑ€ $ Ğ¢Ñ‹ Ğ±Ñ‹ Ğ²Ğ¸Ğ´ĞµĞ» Ğ² ĞºĞ°ĞºĞ¾Ğ¹ Ğ¿Ğ»Ğ°Ğ½? $ Ğ¦Ğ»Ñ Ğ½Ğµ Ğ¿Ñ€Ğ¸ĞµĞ·Ğ¶Ğ°Ğ¹ $ Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ğ±Ğ¾Ğ¸Ñ†Ğ°. Ğ—Ğ°Ñ‚Ğ¾ Ğ½Ğ° Ğ½Ğ¾Ğ³Ñƒ ÑÑ‹Ñ€Ğ¾Ğº Ñ Ğ´Ğ¸Ğ¼Ğ¾Ğ¹, Ñ Ğ´Ğ°Ğ¶Ğµ Ğ½Ğµ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ñ ĞºĞ°Ğº Ñ‚Ñ‹ Ğ´ÑƒĞ¼Ğ°Ğ» Ğ¿Ğ¾Ğ¼Ñ‹Ñ‚ÑŒÑÑ $ Ğ¡Ğ»Ñ‹ÑˆĞ°Ğ¹ÑÑ $ Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾ $ ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ ĞºĞ¾Ğ³Ğ´Ğ° Ñ‚Ñ‹ Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ğ»Ğ¸ Ñ Ğ¿Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ¼ Ğ´Ğ¾Ğ»Ğ³Ğ¾ Ğ´Ğ¾Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒÑÑ $ ĞÑƒ Ğ¿Ğ¾ÑĞ»Ğµ Ñ‚Ğ¾Ğ³Ğ¾, Ñ‡Ñ‚Ğ¾ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¸ Ğ½Ğ°Ğ´Ğ¾ Ğ¾Ñ‚Ğ´Ñ‹Ñ…Ğ°Ğ¹ $ Ğ Ñ‚Ñ‹ Ğ³Ğ´Ğµ? Ğ¢ĞµĞ±Ñ Ğ¶Ğµ ĞµĞ»Ğ° Ğ±ÑƒĞ´ĞµÑˆÑŒ Ñ‚Ğ²Ğ¾Ñ‘? $ Ğ ĞºĞ°Ğº Ğ½Ğ° Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞµ?) $ ĞšĞ¾Ğ½ĞµÑ‡Ğ½Ğ¾ $ ĞŸĞ¾ĞµĞ´ĞµÑˆÑŒ ĞºĞ°Ğº ĞœĞ°Ñ€ÑƒÑÑ? Ğ¢Ğ°Ğº Ñ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ° Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾ $ ĞœĞ°Ğ¼Ğ±Ğµ Ğ¿Ñ€Ğ¸Ğ²ĞµĞ·Ñ‚Ğ¸? $ Ğ”Ğ° Ğ²ÑĞµ Ğ² Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞµ $ Ğ¡Ğ¿Ğ°ÑĞ¸Ğ±Ğ¾ â¤ï¸ $ Ğ¨ĞµÑ€ÑĞ¸Ğ½Ğ° ÑĞµĞ¹Ñ‡Ğ°Ñ Ğ¿Ğ¾Ğ¹Ğ´Ñ‘Ğ¼ 5 ÑĞ¼Ğ°Ğ¹Ğ», Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ñ‚Ğ¾ ÑƒĞ¶Ğµ ÑÑŠĞµĞ»Ğ° $ Ğ¡ÑƒĞ¿ĞµÑ€! Ğ¡Ğ¿Ğ°ÑĞ¸Ğ±Ğ¾ â¤ï¸ $ ĞœĞ¾Ğ¶Ğ½Ğ¾ Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğ° Ğ½Ğ¾ÑƒÑ‚Ğµ Ñ Ñ‚Ğ¾Ğ±Ğ¾Ğ¹ ÑĞµĞ³Ğ¾Ğ´Ğ½Ñ ÑĞ¾Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ÑÑ $ ĞÑƒ Ğ¸ ÑĞ°Ğ¼Ğ° ĞºĞ°Ğ¿ÑÑƒĞ»Ğ°Ğ½Ñƒ Ğ»ÑƒÑ‡ÑˆĞµ Ğ½Ğ° Ğ¿ÑƒÑ…Ğ¾Ğ»ÑŒÑˆĞµ Ğ½Ğ¸ĞºÑ‚Ğ¾ Ğ½Ğµ ÑĞºÑƒÑˆĞ°Ğ»? $ ĞĞµÑ‚ $ Ğ¢Ğ°Ğº Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ñ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ñ‚Ğ¾ Ğ¾ÑĞ²Ğ¾Ğ±Ğ¾Ğ¶ÑƒÑÑŒ $ Ğ£ÑĞ½ÑƒĞ»Ğ° Ğ¸ Ğ¿Ğ¾ĞµĞ»Ğ° Ğ¸ ÑƒĞ·Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ½ Ğ¸ ĞºĞ°ĞºĞ¾Ğ¹ Ñ‚Ğ¾ Ñ€Ğ°ÑÑ‚Ğ°ĞµĞ²Ñ‡Ğ¸Ğº:) $ Ğ•ÑÑ‚ÑŒ Ñ„ÑƒÑÑĞº. Ğ¡Ğ¾ Ğ¼Ğ½Ğ¾Ğ¹ Ğ½Ğ° ĞºÑƒÑ…Ğ½Ñ Ğ¿Ğ¾Ğ´ Ğ´Ğ°Ğ²Ğ½Ğ¾ ÑĞºĞ¸Ğ´Ñ‹Ğ²Ğ°ĞµÑ‚ $ Ğ›Ğ°Ğ½,Ğ°Ñ‚Ğ¾Ğ² ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑĞ°Ğ¼Ğ° \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 4.975870609283447\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, ĞºĞ°Ğº Ğ´ĞµĞ»Ğ°?'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e10e313",
   "metadata": {},
   "source": [
    "ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ñ‡ĞµĞ²Ğ¸Ğ´Ğ½Ğ¾ Ğ½ĞµĞ¿Ğ»Ğ¾Ñ…Ğ¾ Ğ²Ñ‹ÑƒÑ‡Ğ¸Ğ»Ğ° ÑĞ»Ğ¾Ğ²Ğ°, Ğ½Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ´ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ĞºĞ° Ğ½Ğµ Ğ¾Ñ‡ĞµĞ½ÑŒ, ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ¾Ğ±ÑƒÑ‡Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ»ÑŒÑˆĞµ Ğ¸Ğ»Ğ¸ Ğ²Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ´Ñ€ÑƒĞ³ÑƒÑ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a11235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env_kernel",
   "language": "python",
   "name": "tensor_env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
